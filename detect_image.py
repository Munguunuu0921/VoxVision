import torch
import cv2
import os
import easyocr
import numpy as np

# üß† YOLOv5 –∑–∞–≥–≤–∞—Ä—ã–≥ –∞—á–∞–∞–ª–ª–∞—Ö
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', verbose=False)

# üß† EasyOCR –∏–Ω–∏—Ü–∏–∞–ª–∏–∑ —Ö–∏–π—Ö
reader = easyocr.Reader(['en'], gpu=False)

# üñºÔ∏è –ó—É—Ä–∞–≥ –∞—á–∞–∞–ª–ª–∞—Ö (–∑—É—Ä–∞–≥—Ç–∞–π —Ñ–∞–π–ª—ã–Ω –Ω—ç—Ä—ç—ç —ç–Ω–¥ –±–∏—á–Ω—ç)
image_path = "yellow.png"
image = cv2.imread(image_path)
if image is None:
    print("–ó—É—Ä–∞–≥ –æ–ª–¥—Å–æ–Ω–≥“Ø–π:", image_path)
    exit()

# üìç –ö–∞–º–µ—Ä —à–∏–≥ —Ç”©–≤–∏–π–≥ –±–æ–¥–æ—Ö—ã–Ω —Ç—É–ª–¥ –∑—É—Ä–≥–∞–Ω –¥—ç—ç—Ä—Ö ”©—Ä–≥”©–Ω
frame_width = image.shape[1]
center_x = frame_width // 2

# üé® –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ–Ω—ã ”©–Ω–≥”© —Ç–∞–Ω–∏—Ö —Ñ—É–Ω–∫—Ü
def get_dominant_color(cropped_img):
    hsv = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HSV)
    avg_color = hsv.mean(axis=0).mean(axis=0)
    h = avg_color[0]
    if 0 <= h <= 25:
        return 'red'
    elif 26 <= h <= 35:
        return 'yellow'
    elif 36 <= h <= 85:
        return 'green'
    else:
        return 'unknown'

# üì¶ –û–±—å–µ–∫—Ç—É—É–¥—ã–≥ YOLO –∞—à–∏–≥–ª–∞–Ω —Ç–∞–Ω–∏—Ö
results = model(image)
names = results.names
detections = results.xyxy[0]

messages = []

# üîç –û–±—å–µ–∫—Ç –±“Ø—Ä—ç—ç—Ä –¥–∞–≤—Ç–∞–ª—Ç
for *box, conf, cls in detections:
    x1, y1, x2, y2 = map(int, box)
    class_name = names[int(cls)]
    x_center = (x1 + x2) // 2
    side = "left" if x_center < center_x else "right"

    # üö¶ –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ–Ω—ã ”©–Ω–≥”© —à–∞–ª–≥–∞—Ö
    if class_name == "traffic light":
        cropped = image[y1:y2, x1:x2]
        color = get_dominant_color(cropped)
        if color == 'red':
            messages.append("Red light ahead, please stop.")
        elif color == 'green':
            messages.append("Green light ahead, you may go.")
        elif color == 'yellow':
            messages.append("Yellow light ahead, be cautious.")
        else:
            messages.append("Traffic light detected, unclear color.")

    # üöå –ê–≤—Ç–æ–±—É—Å –∏–ª—ç—Ä–≤—ç–ª OCR —Ö–∏–π—Ö
    elif class_name == "bus":
        cropped_bus = image[y1:y2, x1:x2]
        ocr_results = reader.readtext(cropped_bus)
        if ocr_results:
            text = ocr_results[0][1].replace(" ", "").upper()
            messages.append(f"Bus detected, number: {text}")
            os.system(f"say 'Bus number {text}'")

    # üß± –ë—É—Å–∞–¥ –æ–±—å–µ–∫—Ç
    else:
        messages.append(f"{class_name} on the {side}, go {'right' if side == 'left' else 'left'}")

# üó£ –ò–ª—ç—Ä—Å—ç–Ω –∑“Ø–π–ª—Å–∏–π–≥ Mac-–∏–π–Ω `say` –∞—à–∏–≥–ª–∞–Ω —Ö—ç–ª—ç—Ö
if messages:
    output = " | ".join(messages)
    print("üëâ", output)
    os.system(f"say '{output}'")

# üñº –ò–ª—ç—Ä—Å—ç–Ω –æ–±—å–µ–∫—Ç—É—É–¥—Ç–∞–π –∑—É—Ä–∞–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
results.render()
cv2.imshow("Image Detection", results.ims[0])
cv2.waitKey(0)
cv2.destroyAllWindows()
