import torch
import cv2
import os
import numpy as np

# 1. YOLOv5 –∑–∞–≥–≤–∞—Ä—ã–≥ –∞—á–∞–∞–ª–ª–∞–∂ –±–∞–π–Ω–∞
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', verbose=False)

# 2. –í–∏–¥–µ–æ —ç—Ö “Ø“Ø—Å–≤—ç—Ä (0 = –∫–∞–º–µ—Ä, —ç—Å–≤—ç–ª –≤–∏–¥–µ–æ —Ñ–∞–π–ª)
# cap = cv2.VideoCapture("/Users/munguunuu/Documents/yolo zurguud/walking1.mov")
cap = cv2.VideoCapture("http://172.20.10.3:8081/stream")  # IP stream –∞—à–∏–≥–ª–∞—Ö –±–æ–ª

# 3. –ö–∞–º–µ—Ä—ã–Ω —Ñ—Ä–µ–π–º–∏–π–Ω ”©—Ä–≥”©–Ω -> —Ç”©–≤–∏–π–≥ —Ç–æ–¥–æ—Ä—Ö–æ–π–ª–æ—Ö
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
center_x = frame_width // 2

# 4. –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ–Ω—ã ”©–Ω–≥”© —Ç–∞–Ω–∏—Ö —Ñ—É–Ω–∫—Ü
def get_dominant_color(cropped_img):
    hsv = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HSV)
    avg_color = hsv.mean(axis=0).mean(axis=0)
    h = avg_color[0]
    if 0 <= h <= 25:
        return 'red'
    elif 26 <= h <= 35:
        return 'yellow'
    elif 36 <= h <= 85:
        return 'green'
    else:
        return 'unknown'

# 5. “Æ–Ω–¥—Å—ç–Ω real-time loop
while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)
    names = results.names
    detections = results.xyxy[0]
    voice_messages = []

    # –ò–ª—ç—Ä—Å—ç–Ω –±“Ø—Ö –æ–±—å–µ–∫—Ç–∏–π–≥ —à–∞–ª–≥–∞—Ö
    for *box, conf, cls in detections:
        x1, y1, x2, y2 = map(int, box)
        class_id = int(cls)
        class_name = names[class_id]
        label = f"{class_name}"

        # Bounding box –∑—É—Ä–∂ —Ç–µ–∫—Å—Ç –Ω—ç–º—ç—Ö
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, label, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        # ‚û§ –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ–Ω—ã ”©–Ω–≥”© —Ç–∞–Ω–∏—Ö
        if class_name == "traffic light":
            cropped = frame[y1:y2, x1:x2]
            color = get_dominant_color(cropped)
            voice_messages.append(f"Traffic light is {color}")

        # ‚û§ –ó–∞–º—ã–Ω —Ç—ç–º–¥—ç–≥ –±–æ–ª –∑–∞–π, –±–∞–π—Ä–ª–∞–ª —Ç–æ–æ—Ü–æ–æ–ª–∂ —Ö—ç–ª—ç—Ö
        elif "sign" in class_name or "traffic" in class_name:
            height = y2 - y1  # Bounding box-–∏–π–Ω ”©–Ω–¥”©—Ä
            if height > 180:
                distance = "1 meter"
            elif height > 120:
                distance = "2 meters"
            elif height > 80:
                distance = "3 meters"
            else:
                distance = "more than 4 meters"

            # –ó“Ø“Ø–Ω —ç—Å–≤—ç–ª –±–∞—Ä—É—É–Ω —Ç–∞–ª–¥ –±–∞–π–≥–∞–∞–≥ —Ç–æ–≥—Ç–æ–æ—Ö
            object_center_x = (x1 + x2) // 2
            side = "left" if object_center_x < center_x else "right"
            voice_messages.append(f"{class_name} on your {side} at around {distance}")

    # –ò–ª—ç—Ä—Å—ç–Ω –º—ç–¥—ç—ç–ª–ª–∏–π–≥ –¥—É—É–≥–∞–∞—Ä —Ö—ç–ª—ç—Ö
    if voice_messages:
        full_message = " | ".join(voice_messages)
        print("üó£", full_message)
        os.system(f"say '{full_message}'")  # MacOS –¥—ç—ç—Ä –∞–∂–∏–ª–ª–∞–Ω–∞

    # –ò–ª—ç—Ä—Å—ç–Ω –∑“Ø–π–ª—Ç—ç–π –¥“Ø—Ä—Å–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
    cv2.imshow("YOLOv5 - Video Object + Distance Detection", frame)

    # ‚Äòq‚Äô –¥–∞—Ä–≤–∞–ª –≥–∞—Ä–Ω–∞
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# 6. –ù”©”©—Ü —á”©–ª”©”©–ª”©—Ö
cap.release()
cv2.destroyAllWindows()
