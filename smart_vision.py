import torch
import cv2
import os
import easyocr
import numpy as np

# ‚úÖ YOLOv5 –∑–∞–≥–≤–∞—Ä –∞—á–∞–∞–ª–ª–∞–∂ –±–∞–π–Ω–∞
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', verbose=False)

# ‚úÖ EasyOCR-–∏–π–≥ –∞—á–∞–∞–ª–ª–∞–∂ –±–∞–π–Ω–∞
reader = easyocr.Reader(['en'], gpu=False)

# ‚úÖ –ö–∞–º–µ—Ä –∞—Å–∞–∞—Ö
cap = cv2.VideoCapture(0)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
center_x = frame_width // 2

# ‚úÖ –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ–Ω—ã ”©–Ω–≥”© —à–∞–ª–≥–∞—Ö —Ñ—É–Ω–∫—Ü
def get_dominant_color(cropped_img):
    hsv = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2HSV)
    avg_color = hsv.mean(axis=0).mean(axis=0)
    h = avg_color[0]
    if 0 <= h <= 25:
        return 'red'
    elif 26 <= h <= 35:
        return 'yellow'
    elif 36 <= h <= 85:
        return 'green'
    else:
        return 'unknown'

# ‚úÖ “Æ–Ω–¥—Å—ç–Ω —Ü–∏–∫–ª
while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model(frame)
    names = results.names
    detections = results.xyxy[0]
    messages = []

    for *box, conf, cls in detections:
        x1, y1, x2, y2 = map(int, box)
        class_name = names[int(cls)]
        x_center = (x1 + x2) // 2
        side = "left" if x_center < center_x else "right"

        # üéØ –ì—ç—Ä–ª—ç–Ω –¥–æ—Ö–∏–æ
        if class_name == "traffic light":
            cropped = frame[y1:y2, x1:x2]
            color = get_dominant_color(cropped)
            if color == 'red':
                messages.append("Red light ahead, please stop.")
            elif color == 'green':
                messages.append("Green light ahead, you may go.")
            elif color == 'yellow':
                messages.append("Yellow light ahead, be cautious.")
            else:
                messages.append("Traffic light detected, unclear color.")

        # üöå –ê–≤—Ç–æ–±—É—Å —Ç–∞–Ω—å—Å–∞–Ω –±–æ–ª OCR —Ö–∏–π—Ö
        elif class_name == "bus":
            cropped_bus = frame[y1:y2, x1:x2]
            ocr_results = reader.readtext(cropped_bus)
            if ocr_results:
                text = ocr_results[0][1].replace(" ", "").upper()
                messages.append(f"Bus detected, number: {text}")
                os.system(f"say 'Bus number {text}'")

        # üß± –ë—É—Å–∞–¥ –æ–±—å–µ–∫—Ç
        else:
            messages.append(f"{class_name} on the {side}, go {'right' if side == 'left' else 'left'}")

    # üó£ –ë“Ø—Ö –º–µ—Å—Å–µ–∂–∏–π–≥ —Ö—ç–ª—ç—Ö
    if messages:
        output = " | ".join(messages)
        print("üëâ", output)
        os.system(f"say '{output}'")

    # üñº –ò–ª—ç—Ä—Å—ç–Ω bounding box-—É—É–¥—Ç–∞–π –¥“Ø—Ä—Å–∏–π–≥ —Ö–∞—Ä—É—É–ª–∞—Ö
    results.render()
    cv2.imshow("Smart Vision (Mac)", results.ims[0])

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# üßπ –ö–∞–º–µ—Ä –±–æ–ª–æ–Ω —Ü–æ–Ω—Ö —Ö–∞–∞—Ö
cap.release()
cv2.destroyAllWindows()
